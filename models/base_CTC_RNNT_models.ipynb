{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNNR7weY21RPkA25+v6b9ZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/captainkeemo/Dysarthric-Speech-Transcription/blob/main/models/base_CTC_RNNT_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer editdistance --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt16kcAt1rQ5",
        "outputId": "bd38915e-fc4e-4459-b74e-733a3f236903"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m157.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hpptgrn4DkLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2938e40f-4ac5-45ea-890a-aed4a9b5f65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from jiwer import wer, cer\n",
        "import editdistance\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "CyEKx_H6q-hU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler_ctc = GradScaler()\n",
        "scaler_rnnt = GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rJaRsiH21Sv",
        "outputId": "cda25ed1-0123-4142-c7a6-86d0f623179a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae68ad2b3aa0>:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler_ctc = GradScaler()\n",
            "<ipython-input-4-ae68ad2b3aa0>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler_rnnt = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define vocabulary\n",
        "vocab = list(\"abcdefghijklmnopqrstuvwxyz '\") + [\"|\"]\n",
        "char_to_index = {c: i for i, c in enumerate(vocab)}\n",
        "index_to_char = {i: c for c, i in char_to_index.items()}\n"
      ],
      "metadata": {
        "id": "ociJ8CjFruC-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_transcription(text):\n",
        "    text = text.lower().strip()\n",
        "    if '.jpg' in text or '[say' in text or text == 'xxx' or text == '':\n",
        "        return None\n",
        "    return text\n",
        "\n",
        "def decode_sequence(indices, index_to_char):\n",
        "    return ''.join([index_to_char.get(i, '') for i in indices]).replace('|', '').strip()"
      ],
      "metadata": {
        "id": "THjnexGQaZk1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the device\n",
        "def get_device():\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "KmvJJFuWizAY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Mel spectrograms\n",
        "def preprocess_and_save_mel(root_dir, save_dir, sample_rate=16000, n_mels=80, use_gpu=False):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "    mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=n_mels).to(device)\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=48000, new_freq=sample_rate).to(device)\n",
        "\n",
        "    # Step 1: Gather .wav files with tqdm\n",
        "    print(\"Scanning for .wav files...\")\n",
        "    wav_paths = []\n",
        "    for dirpath, _, filenames in tqdm(os.walk(root_dir), desc=\"Scanning folders\"):\n",
        "        for fname in filenames:\n",
        "            if fname.endswith('.wav') and 'wav_headMic' in dirpath:\n",
        "                wav_paths.append(os.path.join(dirpath, fname))\n",
        "\n",
        "    print(f\"Found {len(wav_paths)} .wav files. Starting preprocessing...\")\n",
        "\n",
        "    total_saved = 0\n",
        "\n",
        "    # Step 2: Preprocess with tqdm\n",
        "    for wav_path in tqdm(wav_paths, desc=\"Preprocessing Mel Spectrograms\"):\n",
        "        mel_path = os.path.join(save_dir, os.path.basename(wav_path).replace('.wav', '.pt'))\n",
        "        txt_path = wav_path.replace('wav_headMic', 'prompts').replace('.wav', '.txt')\n",
        "\n",
        "        if not os.path.exists(txt_path) or os.path.exists(mel_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            waveform, sr = torchaudio.load(wav_path)\n",
        "            waveform = waveform.to(device)\n",
        "\n",
        "            if sr != sample_rate:\n",
        "                waveform = resampler(waveform)\n",
        "\n",
        "            mel_spec = mel_transform(waveform).squeeze(0).transpose(0, 1).cpu()\n",
        "\n",
        "            with open(txt_path, 'r', encoding='utf-8') as f:\n",
        "                transcript = f.read().strip().lower()\n",
        "\n",
        "            if '.jpg' in transcript or transcript in ('xxx', '') or '[say' in transcript:\n",
        "                continue\n",
        "\n",
        "            torch.save((mel_spec, transcript), mel_path)\n",
        "            total_saved += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {wav_path}: {e}\")\n",
        "\n",
        "    print(f\"\\nDone: {total_saved} mel .pt files saved to {save_dir}\")\n"
      ],
      "metadata": {
        "id": "hz_eW9R0oUwD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "preprocess_and_save_mel(\n",
        "    root_dir=\"/content/drive/MyDrive/TORGO\",\n",
        "    save_dir=\"/content/drive/MyDrive/TORGO_mel_preprocessed\"\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RZt0Hj-SoZ1E",
        "outputId": "d54552ef-d2a0-48b5-fa09-f9a92c02a40c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\npreprocess_and_save_mel(\\n    root_dir=\"/content/drive/MyDrive/TORGO\",\\n    save_dir=\"/content/drive/MyDrive/TORGO_mel_preprocessed\"\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TorgoDataset(Dataset):\n",
        "    def __init__(self, root_dir, char_to_index, sample_rate=16000,\n",
        "                 items_file=None, use_precomputed=False, mel_dir=None):\n",
        "        self.char_to_index = char_to_index\n",
        "        self.sample_rate = sample_rate\n",
        "        self.use_precomputed = use_precomputed\n",
        "        self.items = []\n",
        "\n",
        "        if self.use_precomputed:\n",
        "            assert mel_dir is not None, \"If using precomputed features, you must provide mel_dir.\"\n",
        "            self.paths = sorted([\n",
        "                os.path.join(mel_dir, f)\n",
        "                for f in os.listdir(mel_dir) if f.endswith('.pt')\n",
        "            ])\n",
        "        else:\n",
        "            self.mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=80)\n",
        "            self.resampler = torchaudio.transforms.Resample(orig_freq=48000, new_freq=sample_rate)\n",
        "\n",
        "            if items_file is not None:\n",
        "                loaded_items = torch.load(items_file)\n",
        "                for wav_fp, text in loaded_items:\n",
        "                    cleaned = clean_transcription(text)\n",
        "                    if cleaned:\n",
        "                        self.items.append((wav_fp, cleaned))\n",
        "            else:\n",
        "                wav_files = []\n",
        "                for dirpath, _, filenames in os.walk(root_dir):\n",
        "                    for fname in filenames:\n",
        "                        if fname.endswith('.wav') and 'wav_headMic' in dirpath:\n",
        "                            wav_files.append(os.path.join(dirpath, fname))\n",
        "\n",
        "                for wav_fp in tqdm(wav_files, desc=f\"Building dataset from .wav files ({len(wav_files)} found)\"):\n",
        "                    txt_fp = wav_fp.replace('wav_headMic', 'prompts').replace('.wav', '.txt')\n",
        "                    if not os.path.exists(txt_fp):\n",
        "                        continue\n",
        "                    with open(txt_fp, 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "                    cleaned = clean_transcription(text)\n",
        "                    if cleaned:\n",
        "                        self.items.append((wav_fp, cleaned))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths) if self.use_precomputed else len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.use_precomputed:\n",
        "            mel_path = self.paths[idx]\n",
        "            mel_spec, transcript = torch.load(mel_path)\n",
        "        else:\n",
        "            wav_path, transcript = self.items[idx]\n",
        "            waveform, sr = torchaudio.load(wav_path)\n",
        "            if sr != self.sample_rate:\n",
        "                waveform = self.resampler(waveform)\n",
        "            mel_spec = self.mel_transform(waveform).squeeze(0).transpose(0, 1)\n",
        "\n",
        "        target = torch.tensor([self.char_to_index[c] for c in transcript if c in self.char_to_index], dtype=torch.long)\n",
        "        return mel_spec, target\n"
      ],
      "metadata": {
        "id": "NF-gwWrBq6zj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    features, targets = zip(*batch)\n",
        "\n",
        "    # Compute original lengths\n",
        "    input_lengths = torch.tensor([feat.size(0) for feat in features], dtype=torch.long)\n",
        "    target_lengths = torch.tensor([len(tgt) for tgt in targets], dtype=torch.long)\n",
        "\n",
        "    # Pad features (time dimension is dim 0)\n",
        "    padded_features = pad_sequence(features, batch_first=True)  # shape: [B, T, F]\n",
        "\n",
        "    # Pad targets for inspection (not used in loss)\n",
        "    padded_targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "\n",
        "    return padded_features, input_lengths, padded_targets, target_lengths\n"
      ],
      "metadata": {
        "id": "IVPwDf-um_OJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the full RNN-T model with encoder, decoder, and joiner\n",
        "class RNNTModel(nn.Module):\n",
        "    def __init__(self, input_dim=80, vocab_size=len(vocab), hidden_dim=128, embed_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.decoder = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.joiner = nn.Linear(hidden_dim * 2 + hidden_dim, vocab_size)  # enc (bi) + dec (uni)\n",
        "\n",
        "    def forward(self, encoder_input, target_input):\n",
        "        # encoder_input: [B, T_enc, 80]\n",
        "        # target_input: [B, T_dec]\n",
        "        enc_out, _ = self.encoder(encoder_input)  # [B, T_enc, 2*H]\n",
        "        dec_emb = self.embed(target_input)        # [B, T_dec, E]\n",
        "        dec_out, _ = self.decoder(dec_emb)        # [B, T_dec, H]\n",
        "\n",
        "        # Expand for joiner broadcasting\n",
        "        enc_exp = enc_out.unsqueeze(2)            # [B, T_enc, 1, 2H]\n",
        "        dec_exp = dec_out.unsqueeze(1)            # [B, 1, T_dec, H]\n",
        "\n",
        "        # Joiner: concat and project\n",
        "        enc_b, t_enc, _, h_enc = enc_exp.shape\n",
        "        dec_b, _, t_dec, h_dec = dec_exp.shape\n",
        "        assert enc_b == dec_b\n",
        "\n",
        "        enc_rep = enc_exp.expand(-1, t_enc, t_dec, -1)  # [B, T_enc, T_dec, 2H]\n",
        "        dec_rep = dec_exp.expand(-1, t_enc, t_dec, -1)  # [B, T_enc, T_dec, H]\n",
        "\n",
        "        joined = torch.cat([enc_rep, dec_rep], dim=-1)  # [B, T_enc, T_dec, 3H]\n",
        "        logits = self.joiner(joined)                    # [B, T_enc, T_dec, V]\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "AmPJl7HInLf0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CTC Model Class\n",
        "class CTCModel(nn.Module):\n",
        "    def __init__(self, input_dim=80, hidden_dim=128, vocab_size=len(vocab), num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True, num_layers=num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        logits = self.fc(x)\n",
        "        return logits  # shape: [B, T, vocab_size]\n"
      ],
      "metadata": {
        "id": "SriUtsBU1Yoh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BeamSearch:\n",
        "    def __init__(self, beam_width, vocab_size, blank_index):\n",
        "        self.beam_width = beam_width\n",
        "        self.vocab_size = vocab_size\n",
        "        self.blank_index = blank_index\n",
        "\n",
        "    def decode(self, logits):\n",
        "        batch_size = logits.size(1)\n",
        "        T = logits.size(0)\n",
        "        results = []\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            beams = [([], 0.0)]\n",
        "            for t in range(T):\n",
        "                new_beams = []\n",
        "                log_probs = F.log_softmax(logits[t, b], dim=-1)\n",
        "                topk = torch.topk(log_probs, self.beam_width)\n",
        "\n",
        "                for seq, score in beams:\n",
        "                    for i in range(self.beam_width):\n",
        "                        token = topk.indices[i].item()\n",
        "                        new_score = score + topk.values[i].item()\n",
        "                        if token == self.blank_index:\n",
        "                            new_beams.append((seq, new_score))\n",
        "                        else:\n",
        "                            new_beams.append((seq + [token], new_score))\n",
        "\n",
        "                new_beams.sort(key=lambda x: x[1], reverse=True)\n",
        "                beams = new_beams[:self.beam_width]\n",
        "\n",
        "            best_seq = max(beams, key=lambda x: x[1])[0]\n",
        "            results.append(best_seq)  # Changed from results.append([best_seq])\n",
        "\n",
        "        # Ensure results is always a list of lists even with beam_width=1\n",
        "        results = [[item] if isinstance(item, int) else item for item in results]\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "5t3s_kBfeuMl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute WER, CER, Edit Distance\n",
        "from torchaudio.functional import edit_distance as torchaudio_edit_distance\n",
        "from jiwer import wer, cer\n",
        "\n",
        "def compute_wer_cer(preds, input_lens, targets, target_lens, index_to_char):\n",
        "    total_wer, total_cer = 0.0, 0.0\n",
        "    offset = 0\n",
        "    valid_examples = 0\n",
        "\n",
        "    for i in range(len(preds)):\n",
        "        tlen = target_lens[i].item()\n",
        "        if tlen == 0:\n",
        "            continue  # skip empty targets\n",
        "\n",
        "        target_slice = targets[offset:offset + tlen]\n",
        "        target_seq = target_slice.view(-1).tolist()\n",
        "        offset += tlen\n",
        "\n",
        "        pred_seq = preds[i] if isinstance(preds[i], (list, tuple)) else [preds[i]]\n",
        "        pred_str = ''.join([index_to_char.get(p, '') for p in pred_seq])\n",
        "        target_str = ''.join([index_to_char.get(t, '') for t in target_seq])\n",
        "\n",
        "        if not target_str.strip():\n",
        "            continue  # skip if the reference string is still empty\n",
        "\n",
        "        total_wer += wer(target_str, pred_str)\n",
        "        total_cer += cer(target_str, pred_str)\n",
        "        valid_examples += 1\n",
        "\n",
        "    if valid_examples == 0:\n",
        "        return 1.0, 1.0  # fallback if no valid examples\n",
        "    return total_wer / valid_examples, total_cer / valid_examples\n",
        "\n"
      ],
      "metadata": {
        "id": "E4U-b7ik5JvW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import cer\n",
        "\n",
        "def decode_indices(indices, index_to_char):\n",
        "    return ''.join([index_to_char[i] for i in indices if i in index_to_char]).replace('|', ' ').strip()\n",
        "\n",
        "def compute_cer_accuracy(preds, targets, target_lens, index_to_char):\n",
        "    offset = 0\n",
        "    all_refs, all_hyps = [], []\n",
        "    for i, tlen in enumerate(target_lens):\n",
        "        ref = ''.join([index_to_char[x.item()] for x in targets[offset:offset + tlen]])\n",
        "        hyp = ''.join([index_to_char[x] for x in preds[i]])\n",
        "        all_refs.append(ref)\n",
        "        all_hyps.append(hyp)\n",
        "        offset += tlen\n",
        "    return 1.0 - cer(all_refs, all_hyps)\n"
      ],
      "metadata": {
        "id": "ClzVUYm6nHqP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Greedy decoding for character prediction from model output\n",
        "def greedy_decode(logits, input_lens, blank_index):\n",
        "    pred = logits.argmax(dim=2)\n",
        "    results = []\n",
        "    for i in range(pred.size(0)):\n",
        "        tokens, prev = [], None\n",
        "        for j in range(input_lens[i]):\n",
        "            idx = pred[i, j].item()\n",
        "            if idx != blank_index and idx != prev:\n",
        "                tokens.append(idx)\n",
        "            prev = idx\n",
        "        results.append(tokens)\n",
        "    return results"
      ],
      "metadata": {
        "id": "CtH_sjsInDa4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_ctc(model, train_loader, val_loader, optimizer, loss_fn, index_to_char,\n",
        "              device, epochs=20, patience=5, blank_idx=1, beam_width=5):\n",
        "\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    wait = 0\n",
        "\n",
        "    train_loss_hist, val_loss_hist = [], []\n",
        "    train_wer_hist, val_wer_hist = [], []\n",
        "    train_cer_hist, val_cer_hist = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        model.train()\n",
        "        train_loss, train_wer, train_cer = 0, 0, 0\n",
        "\n",
        "        train_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "        for feats, feat_lens, targets, target_lens in train_bar:\n",
        "            feats, feat_lens = feats.to(device), feat_lens.to(device)\n",
        "            targets, target_lens = targets.to(device), target_lens.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(feats)\n",
        "            log_probs = logits.log_softmax(2).transpose(0, 1)\n",
        "            loss = loss_fn(log_probs, targets, feat_lens, target_lens)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                decoder = BeamSearch(beam_width, logits.size(2), blank_idx)\n",
        "                raw_preds = decoder.decode(log_probs.cpu())\n",
        "\n",
        "                preds = [beam[0] if isinstance(beam[0], (list, tuple)) else beam for beam in raw_preds]\n",
        "                preds = [p if isinstance(p, list) else [p] for p in preds]\n",
        "\n",
        "                wer_score, cer_score = compute_wer_cer(preds, feat_lens.cpu(), targets.cpu(), target_lens.cpu(), index_to_char)\n",
        "                train_wer += wer_score\n",
        "                train_cer += cer_score\n",
        "\n",
        "            train_bar.set_postfix(loss=loss.item(), WER=wer_score, CER=cer_score)\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_wer /= len(train_loader)\n",
        "        train_cer /= len(train_loader)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_loss, val_wer, val_cer = 0, 0, 0\n",
        "        val_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for feats, feat_lens, targets, target_lens in val_bar:\n",
        "                feats, feat_lens = feats.to(device), feat_lens.to(device)\n",
        "                targets, target_lens = targets.to(device), target_lens.to(device)\n",
        "\n",
        "                logits = model(feats)\n",
        "                log_probs = logits.log_softmax(2).transpose(0, 1)\n",
        "                loss = loss_fn(log_probs, targets, feat_lens, target_lens)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                decoder = BeamSearch(beam_width, logits.size(2), blank_idx)\n",
        "                raw_preds = decoder.decode(log_probs.cpu())\n",
        "\n",
        "                preds = [beam[0] if isinstance(beam[0], (list, tuple)) else beam for beam in raw_preds]\n",
        "                preds = [p if isinstance(p, list) else [p] for p in preds]\n",
        "\n",
        "                wer_score, cer_score = compute_wer_cer(preds, feat_lens.cpu(), targets.cpu(), target_lens.cpu(), index_to_char)\n",
        "                val_wer += wer_score\n",
        "                val_cer += cer_score\n",
        "\n",
        "                val_bar.set_postfix(loss=loss.item(), WER=wer_score, CER=cer_score)\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_wer /= len(val_loader)\n",
        "        val_cer /= len(val_loader)\n",
        "\n",
        "        train_loss_hist.append(train_loss)\n",
        "        val_loss_hist.append(val_loss)\n",
        "        train_wer_hist.append(train_wer)\n",
        "        val_wer_hist.append(val_wer)\n",
        "        train_cer_hist.append(train_cer)\n",
        "        val_cer_hist.append(val_cer)\n",
        "\n",
        "        print(f\"[CTC] Epoch {epoch+1}: \"\n",
        "              f\"Train Loss={train_loss:.4f}, WER={train_wer:.4f}, CER={train_cer:.4f} | \"\n",
        "              f\"Val Loss={val_loss:.4f}, WER={val_wer:.4f}, CER={val_cer:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_ctc_model.pt')\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    return train_loss_hist, val_loss_hist, train_wer_hist, val_wer_hist, train_cer_hist, val_cer_hist\n"
      ],
      "metadata": {
        "id": "KmX9KIL03Qb2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_rnnt(model, train_loader, val_loader, optimizer, loss_fn, index_to_char,\n",
        "               device, epochs=20, patience=5, blank_idx=1, beam_width=5):\n",
        "\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    wait = 0\n",
        "\n",
        "    train_loss_hist, val_loss_hist = [], []\n",
        "    train_wer_hist, val_wer_hist = [], []\n",
        "    train_cer_hist, val_cer_hist = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss, train_wer, train_cer = 0, 0, 0\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training (RNN-T)\")\n",
        "        for feats, feat_lens, targets, target_lens in train_pbar:\n",
        "            feats, feat_lens = feats.to(device), feat_lens.to(device)\n",
        "            targets, target_lens = targets.to(device), target_lens.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(feats, targets)\n",
        "            T_enc = logits.shape[1]\n",
        "            T_dec = logits.shape[2]\n",
        "            min_len = min(T_enc, T_dec, feat_lens.max().item())\n",
        "            logits = logits[:, torch.arange(min_len), torch.arange(min_len), :]\n",
        "            log_probs = logits.log_softmax(2).transpose(0, 1)\n",
        "            feat_lens = torch.clamp(feat_lens, max=log_probs.shape[0])\n",
        "\n",
        "            loss = loss_fn(log_probs, targets, feat_lens, target_lens)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                decoder = BeamSearch(beam_width, logits.size(2), blank_idx)\n",
        "                preds = decoder.decode(log_probs.cpu())\n",
        "                wer_score, cer_score = compute_wer_cer(preds, feat_lens.cpu(), targets.cpu(), target_lens.cpu(), index_to_char)\n",
        "                train_wer += wer_score\n",
        "                train_cer += cer_score\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_wer /= len(train_loader)\n",
        "        train_cer /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_wer, val_cer = 0, 0, 0\n",
        "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1} - Validation (RNN-T)\")\n",
        "        with torch.no_grad():\n",
        "            for feats, feat_lens, targets, target_lens in val_pbar:\n",
        "                feats, feat_lens = feats.to(device), feat_lens.to(device)\n",
        "                targets, target_lens = targets.to(device), target_lens.to(device)\n",
        "\n",
        "                logits = model(feats, targets)\n",
        "                T_enc = logits.shape[1]\n",
        "                T_dec = logits.shape[2]\n",
        "                min_len = min(T_enc, T_dec, feat_lens.max().item())\n",
        "                logits = logits[:, torch.arange(min_len), torch.arange(min_len), :]\n",
        "                log_probs = logits.log_softmax(2).transpose(0, 1)\n",
        "                feat_lens = torch.clamp(feat_lens, max=log_probs.shape[0])\n",
        "\n",
        "                loss = loss_fn(log_probs, targets, feat_lens, target_lens)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                decoder = BeamSearch(beam_width, logits.size(2), blank_idx)\n",
        "                preds = decoder.decode(log_probs.cpu())\n",
        "                wer_score, cer_score = compute_wer_cer(preds, feat_lens.cpu(), targets.cpu(), target_lens.cpu(), index_to_char)\n",
        "                val_wer += wer_score\n",
        "                val_cer += cer_score\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_wer /= len(val_loader)\n",
        "        val_cer /= len(val_loader)\n",
        "\n",
        "        train_loss_hist.append(train_loss)\n",
        "        val_loss_hist.append(val_loss)\n",
        "        train_wer_hist.append(train_wer)\n",
        "        val_wer_hist.append(val_wer)\n",
        "        train_cer_hist.append(train_cer)\n",
        "        val_cer_hist.append(val_cer)\n",
        "\n",
        "        print(f\"[RNN-T] Epoch {epoch+1}: Train Loss={train_loss:.4f}, WER={train_wer:.4f}, CER={train_cer:.4f} | \"\n",
        "              f\"Val Loss={val_loss:.4f}, WER={val_wer:.4f}, CER={val_cer:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_rnnt_model.pt')\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    return train_loss_hist, val_loss_hist, train_wer_hist, val_wer_hist, train_cer_hist, val_cer_hist\n"
      ],
      "metadata": {
        "id": "KP0liDFI3U1W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_plot_model(\n",
        "    model, test_loader, loss_fn, index_to_char, device,\n",
        "    blank_idx=1, use_beam=True, beam_width=5, model_type=\"ctc\"\n",
        "):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    total_wer = 0\n",
        "    total_cer = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for feats, feat_lens, targets, target_lens in test_loader:\n",
        "            feats, feat_lens = feats.to(device), feat_lens.to(device)\n",
        "            targets, target_lens = targets.to(device), target_lens.to(device)\n",
        "\n",
        "            if model_type == \"rnnt\":\n",
        "                logits = model(feats, targets)\n",
        "                T_enc = logits.shape[1]\n",
        "                T_dec = logits.shape[2]\n",
        "                min_len = min(T_enc, T_dec, feat_lens.max().item())\n",
        "                logits = logits[:, torch.arange(min_len), torch.arange(min_len), :]\n",
        "            else:\n",
        "                logits = model(feats)\n",
        "\n",
        "            log_probs = logits.log_softmax(2).transpose(0, 1)\n",
        "\n",
        "            # Clamp feat_lens in case it exceeds time dim of logits\n",
        "            feat_lens = torch.clamp(feat_lens, max=log_probs.size(0))\n",
        "\n",
        "            loss = loss_fn(log_probs, targets, feat_lens, target_lens)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Decode predictions\n",
        "            if use_beam:\n",
        "                decoder = BeamSearch(beam_width, logits.size(-1), blank_idx)\n",
        "                preds = decoder.decode(log_probs.cpu())\n",
        "            else:\n",
        "                preds = logits.cpu().argmax(2)  # greedy decode\n",
        "                preds = [pred[:feat_lens[i]].tolist() for i, pred in enumerate(preds)]\n",
        "\n",
        "            wer_score, cer_score = compute_wer_cer(preds, feat_lens.cpu(), targets.cpu(), target_lens.cpu(), index_to_char)\n",
        "            total_wer += wer_score\n",
        "            total_cer += cer_score\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    avg_wer = total_wer / len(test_loader)\n",
        "    avg_cer = total_cer / len(test_loader)\n",
        "\n",
        "    print(f\"[{model_type.upper()}] Test Loss={avg_loss:.4f}, WER={avg_wer:.4f}, CER={avg_cer:.4f}\")\n",
        "\n",
        "    return avg_loss, avg_wer, avg_cer\n"
      ],
      "metadata": {
        "id": "1HzSEUfL_WS9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/TORGO\"\n",
        "\n",
        "# Load dataset\n",
        "#dataset = TorgoDataset(data_dir, char_to_index)\n",
        "#torch.save(dataset.items, '/content/drive/MyDrive/torgo_items.pt')\n",
        "dataset = TorgoDataset(\n",
        "    root_dir=\"/content/drive/MyDrive/TORGO\",  # still required for structure\n",
        "    char_to_index=char_to_index,\n",
        "    use_precomputed=True,\n",
        "    mel_dir=\"/content/drive/MyDrive/TORGO_mel_preprocessed\"\n",
        ")\n",
        "print(f\"Dataset length: {len(dataset)}\")\n",
        "\n",
        "# Calculate lengths\n",
        "total_len = len(dataset)\n",
        "train_len = int(0.7 * total_len)\n",
        "val_len = int(0.1 * total_len)\n",
        "test_len = total_len - train_len - val_len\n",
        "\n",
        "# Perform split\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn, pin_memory=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtyxmwrT3T8E",
        "outputId": "e19cb25e-6aa2-4caa-ee2e-96d7520bb371"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: 993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Train CTC model\n",
        "model_ctc = CTCModel()\n",
        "optimizer_ctc = torch.optim.Adam(model_ctc.parameters(), lr=1e-5)\n",
        "loss_fn_ctc = nn.CTCLoss(blank=char_to_index['|'], zero_infinity=True)\n",
        "device = get_device()\n",
        "\n",
        "start_time = time.time()\n",
        "ctc_train_loss, ctc_val_loss, ctc_train_wer, ctc_val_wer, ctc_train_cer, ctc_val_cer = train_ctc(\n",
        "    model=model_ctc,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer_ctc,\n",
        "    loss_fn=loss_fn_ctc,\n",
        "    index_to_char=index_to_char,\n",
        "    epochs=50,\n",
        "    patience=3,\n",
        "    device=device\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Baseline CTC Training time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDjqGXDa9QaN",
        "outputId": "73f30240-67cd-4ebc-fcd4-eb80b04b547d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 1: Train Loss=109.3613, WER=2.8536, CER=1.7385 | Val Loss=112.8398, WER=1.4667, CER=1.6343\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 2: Train Loss=109.1865, WER=1.7649, CER=1.6454 | Val Loss=112.5942, WER=1.1667, CER=1.6357\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 3: Train Loss=108.7976, WER=1.2526, CER=1.8312 | Val Loss=112.3103, WER=1.1667, CER=1.6365\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 4: Train Loss=108.6299, WER=1.1828, CER=1.5666 | Val Loss=111.9798, WER=1.1667, CER=1.6389\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 5: Train Loss=108.3899, WER=1.2594, CER=1.5588 | Val Loss=111.5968, WER=1.1111, CER=1.6419\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 6: Train Loss=107.8791, WER=1.0952, CER=1.6558 | Val Loss=111.1653, WER=1.1111, CER=1.6471\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 7: Train Loss=107.6187, WER=1.0545, CER=1.6357 | Val Loss=110.6840, WER=1.0556, CER=1.6490\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 8: Train Loss=107.0574, WER=1.0928, CER=1.6609 | Val Loss=110.1566, WER=1.0556, CER=1.6513\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 9: Train Loss=106.5746, WER=1.0996, CER=1.5028 | Val Loss=109.5877, WER=1.1111, CER=1.6541\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 10: Train Loss=106.0998, WER=1.0615, CER=1.5707 | Val Loss=108.9754, WER=1.1111, CER=1.6563\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 11: Train Loss=105.2394, WER=1.0899, CER=1.8223 | Val Loss=108.3137, WER=1.0556, CER=1.6569\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 12: Train Loss=104.9297, WER=1.0247, CER=1.7580 | Val Loss=107.6030, WER=1.0000, CER=1.6582\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 13: Train Loss=104.1397, WER=1.0152, CER=1.7930 | Val Loss=106.8384, WER=1.0000, CER=1.6607\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 14: Train Loss=103.2422, WER=1.0000, CER=2.0476 | Val Loss=106.0067, WER=1.0556, CER=1.6619\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 15: Train Loss=102.4248, WER=1.0000, CER=1.4546 | Val Loss=105.1074, WER=1.0556, CER=1.6624\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 16: Train Loss=101.5875, WER=1.0000, CER=1.6027 | Val Loss=104.1183, WER=1.0000, CER=1.6626\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 17: Train Loss=100.6315, WER=1.0000, CER=1.5355 | Val Loss=103.0395, WER=1.0000, CER=1.6627\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 18: Train Loss=99.5155, WER=1.0000, CER=1.7014 | Val Loss=101.8442, WER=1.0000, CER=1.6627\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 19: Train Loss=98.2418, WER=1.0091, CER=1.9350 | Val Loss=100.5142, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 20: Train Loss=96.8716, WER=1.0000, CER=1.5721 | Val Loss=99.0293, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 21: Train Loss=95.3872, WER=1.0000, CER=1.6689 | Val Loss=97.3591, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 22: Train Loss=93.9920, WER=1.0000, CER=1.7286 | Val Loss=95.5007, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 23: Train Loss=91.8259, WER=1.0000, CER=1.8599 | Val Loss=93.3420, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 24: Train Loss=89.6339, WER=1.0000, CER=1.6848 | Val Loss=90.9074, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 25: Train Loss=87.2854, WER=1.0000, CER=1.6428 | Val Loss=88.1054, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 26: Train Loss=84.3280, WER=1.0000, CER=1.4924 | Val Loss=84.8311, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 27: Train Loss=81.0130, WER=1.0000, CER=1.4174 | Val Loss=81.0193, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 28: Train Loss=77.0639, WER=1.0000, CER=1.5182 | Val Loss=76.5658, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 29: Train Loss=72.4868, WER=1.0000, CER=1.7755 | Val Loss=71.3528, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 30: Train Loss=67.0914, WER=1.0000, CER=1.6398 | Val Loss=65.3599, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 31: Train Loss=60.9146, WER=1.0000, CER=1.6259 | Val Loss=58.4344, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 32: Train Loss=53.9220, WER=1.0000, CER=1.7627 | Val Loss=50.6937, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 33: Train Loss=46.1040, WER=1.0000, CER=1.8512 | Val Loss=42.3982, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 34: Train Loss=37.9517, WER=1.0000, CER=1.6891 | Val Loss=34.1063, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 35: Train Loss=30.0345, WER=1.0000, CER=1.6603 | Val Loss=26.4507, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 36: Train Loss=23.2047, WER=1.0000, CER=1.5000 | Val Loss=20.1858, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 37: Train Loss=17.7532, WER=1.0000, CER=1.6795 | Val Loss=15.5310, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 38: Train Loss=13.8585, WER=1.0000, CER=1.5851 | Val Loss=12.2413, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 39: Train Loss=11.0868, WER=1.0000, CER=1.5611 | Val Loss=10.0523, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 40: Train Loss=9.2588, WER=1.0000, CER=1.7217 | Val Loss=8.5392, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 41: Train Loss=7.9791, WER=1.0000, CER=1.6356 | Val Loss=7.4788, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 42: Train Loss=7.0524, WER=1.0000, CER=1.6977 | Val Loss=6.7387, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 43: Train Loss=6.4079, WER=1.0000, CER=1.7307 | Val Loss=6.1826, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 44: Train Loss=5.9077, WER=1.0000, CER=1.8896 | Val Loss=5.7613, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 45: Train Loss=5.5427, WER=1.0000, CER=1.6540 | Val Loss=5.4354, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 46: Train Loss=5.2422, WER=1.0000, CER=1.5971 | Val Loss=5.1754, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 47: Train Loss=5.0080, WER=1.0000, CER=1.7144 | Val Loss=4.9656, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 48: Train Loss=4.8164, WER=1.0000, CER=1.6323 | Val Loss=4.7971, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 49: Train Loss=4.6583, WER=1.0000, CER=1.7489 | Val Loss=4.6565, WER=1.0000, CER=1.6631\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CTC] Epoch 50: Train Loss=4.5330, WER=1.0000, CER=1.5944 | Val Loss=4.5413, WER=1.0000, CER=1.6631\n",
            "Baseline CTC Training time: 4052.1429607868195 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Train RNN-T model\n",
        "model_rnnt = RNNTModel()\n",
        "optimizer_rnnt = torch.optim.Adam(model_rnnt.parameters(), lr=1e-4)\n",
        "loss_fn_rnnt = nn.CTCLoss(blank=char_to_index['|'], zero_infinity=True)\n",
        "device = get_device()\n",
        "\n",
        "start_time = time.time()\n",
        "rnnt_train_loss, rnnt_val_loss, rnnt_train_wer, rnnt_val_wer, rnnt_train_cer, rnnt_val_cer = train_rnnt(\n",
        "    model=model_rnnt,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer_rnnt,\n",
        "    loss_fn=loss_fn_rnnt,\n",
        "    index_to_char=index_to_char,\n",
        "    epochs=50,\n",
        "    patience=3,\n",
        "    device=device\n",
        ")\n",
        "end_time = time.time()\n",
        "print(f\"Baseline RNN-T Training time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOs1T3K29QQ1",
        "outputId": "9d5e1920-8ac9-4468-bd5f-55dc814bb0d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 1 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 1: Train Loss=36.4078, WER=1.0000, CER=0.9906 | Val Loss=39.6374, WER=1.0000, CER=0.9967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.01it/s]\n",
            "Epoch 2 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 2: Train Loss=37.1022, WER=1.0000, CER=0.9983 | Val Loss=36.2681, WER=1.0000, CER=0.9999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
            "Epoch 3 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 3: Train Loss=32.2876, WER=1.0000, CER=0.9998 | Val Loss=31.9682, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 4 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 4: Train Loss=27.7080, WER=1.0000, CER=1.0000 | Val Loss=26.4101, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 5 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 5: Train Loss=21.7209, WER=1.0000, CER=1.0000 | Val Loss=19.5983, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
            "Epoch 6 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 6: Train Loss=14.7944, WER=1.0000, CER=1.0000 | Val Loss=12.9566, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.10it/s]\n",
            "Epoch 7 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 7: Train Loss=9.7065, WER=1.0000, CER=1.0000 | Val Loss=7.2053, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.05it/s]\n",
            "Epoch 8 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 8: Train Loss=5.3527, WER=1.0000, CER=1.0000 | Val Loss=4.0405, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n",
            "Epoch 9 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 9: Train Loss=3.8283, WER=1.0000, CER=1.0000 | Val Loss=3.7272, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
            "Epoch 10 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 10: Train Loss=3.7368, WER=1.0000, CER=1.0000 | Val Loss=3.6923, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 11 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 11: Train Loss=3.6802, WER=1.0000, CER=1.0000 | Val Loss=3.6297, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.10it/s]\n",
            "Epoch 12 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 12: Train Loss=3.6008, WER=1.0000, CER=1.0000 | Val Loss=3.5786, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n",
            "Epoch 13 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 13: Train Loss=3.5750, WER=1.0000, CER=1.0000 | Val Loss=3.5439, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 14 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 14: Train Loss=3.5306, WER=1.0000, CER=1.0000 | Val Loss=3.5162, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.11it/s]\n",
            "Epoch 15 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 15: Train Loss=3.5011, WER=1.0000, CER=1.0000 | Val Loss=3.4924, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.11it/s]\n",
            "Epoch 16 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 16: Train Loss=3.4728, WER=1.0000, CER=1.0000 | Val Loss=3.4717, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 17 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 17: Train Loss=3.4534, WER=1.0000, CER=1.0000 | Val Loss=3.4541, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
            "Epoch 18 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 18: Train Loss=3.4429, WER=1.0000, CER=1.0000 | Val Loss=3.4384, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 19 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 19: Train Loss=3.4261, WER=1.0000, CER=1.0000 | Val Loss=3.4246, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 20 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 20: Train Loss=3.4133, WER=1.0000, CER=1.0000 | Val Loss=3.4119, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
            "Epoch 21 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 21: Train Loss=3.3930, WER=1.0000, CER=1.0000 | Val Loss=3.4013, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 22 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 22: Train Loss=3.4118, WER=1.0000, CER=1.0000 | Val Loss=3.3915, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.13it/s]\n",
            "Epoch 23 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 23: Train Loss=3.3730, WER=1.0000, CER=1.0000 | Val Loss=3.3831, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 24 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 24: Train Loss=3.3707, WER=1.0000, CER=1.0000 | Val Loss=3.3755, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 25 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 25: Train Loss=3.3691, WER=1.0000, CER=1.0000 | Val Loss=3.3670, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 26 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 26: Train Loss=3.3669, WER=1.0000, CER=1.0000 | Val Loss=3.3587, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 27 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 27: Train Loss=3.3448, WER=1.0000, CER=1.0000 | Val Loss=3.3515, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 28 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 28: Train Loss=3.3544, WER=1.0000, CER=1.0000 | Val Loss=3.3448, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 29 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 29: Train Loss=3.3378, WER=1.0000, CER=1.0000 | Val Loss=3.3377, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
            "Epoch 30 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 30: Train Loss=3.3359, WER=1.0000, CER=1.0000 | Val Loss=3.3306, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.13it/s]\n",
            "Epoch 31 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 31: Train Loss=3.3228, WER=1.0000, CER=1.0000 | Val Loss=3.3247, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 32 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 32: Train Loss=3.3292, WER=1.0000, CER=1.0000 | Val Loss=3.3193, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 33 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 33: Train Loss=3.3189, WER=1.0000, CER=1.0000 | Val Loss=3.3127, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 34 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 34: Train Loss=3.3186, WER=1.0000, CER=1.0000 | Val Loss=3.3064, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 35 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 35: Train Loss=3.2952, WER=1.0000, CER=1.0000 | Val Loss=3.2991, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 36 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 36: Train Loss=3.2976, WER=1.0000, CER=1.0000 | Val Loss=3.2927, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 37 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 37: Train Loss=3.2928, WER=1.0000, CER=1.0000 | Val Loss=3.2871, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.18it/s]\n",
            "Epoch 38 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 38: Train Loss=3.2734, WER=1.0000, CER=1.0000 | Val Loss=3.2815, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
            "Epoch 39 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 39: Train Loss=3.2856, WER=1.0000, CER=1.0000 | Val Loss=3.2759, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.14it/s]\n",
            "Epoch 40 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 40: Train Loss=3.2603, WER=1.0000, CER=1.0000 | Val Loss=3.2689, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.10it/s]\n",
            "Epoch 41 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 41: Train Loss=3.2707, WER=1.0000, CER=1.0000 | Val Loss=3.2617, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.05it/s]\n",
            "Epoch 42 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 42: Train Loss=3.2682, WER=1.0000, CER=1.0000 | Val Loss=3.2549, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 43 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 43: Train Loss=3.2448, WER=1.0000, CER=1.0000 | Val Loss=3.2486, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
            "Epoch 44 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 44: Train Loss=3.2622, WER=1.0000, CER=1.0000 | Val Loss=3.2428, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
            "Epoch 45 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 45: Train Loss=3.2451, WER=1.0000, CER=1.0000 | Val Loss=3.2361, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 46 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 46: Train Loss=3.2331, WER=1.0000, CER=1.0000 | Val Loss=3.2301, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 47 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 47: Train Loss=3.2382, WER=1.0000, CER=1.0000 | Val Loss=3.2234, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.09it/s]\n",
            "Epoch 48 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 48: Train Loss=3.2219, WER=1.0000, CER=1.0000 | Val Loss=3.2167, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49 - Training (RNN-T): 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
            "Epoch 49 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 49: Train Loss=3.2211, WER=1.0000, CER=1.0000 | Val Loss=3.2091, WER=1.0000, CER=1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50 - Training (RNN-T): 100%|██████████| 11/11 [00:09<00:00,  1.11it/s]\n",
            "Epoch 50 - Validation (RNN-T): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNN-T] Epoch 50: Train Loss=3.2218, WER=1.0000, CER=1.0000 | Val Loss=3.2028, WER=1.0000, CER=1.0000\n",
            "Baseline RNN-T Training time: 579.5520398616791 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctc_results = evaluate_and_plot_model(\n",
        "    model=model_ctc,\n",
        "    test_loader=test_loader,\n",
        "    loss_fn=loss_fn_ctc,\n",
        "    index_to_char=index_to_char,\n",
        "    device='cuda',\n",
        "    blank_idx=char_to_index['|'],\n",
        "    use_beam=True,\n",
        "    beam_width=5,\n",
        "    model_type=\"ctc\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNAfDr0I3nie",
        "outputId": "15b4b691-2f90-4f71-d7d6-0a3dc5c432cd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test - CTC] Loss: 4.4558 | WER: 1.0000 | CER: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnnt_results = evaluate_and_plot_model(\n",
        "    model=model_rnnt,\n",
        "    test_loader=test_loader,\n",
        "    loss_fn=loss_fn_rnnt,\n",
        "    index_to_char=index_to_char,\n",
        "    device='cuda',\n",
        "    blank_idx=char_to_index['|'],\n",
        "    use_beam=True,\n",
        "    beam_width=5,\n",
        "    model_type=\"rnnt\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewfLTD8M35r8",
        "outputId": "d62e2dc7-2569-417b-ed1e-0d2a4d2a49b7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RNNT] Test Loss=3.2369, WER=1.0000, CER=1.0000\n"
          ]
        }
      ]
    }
  ]
}